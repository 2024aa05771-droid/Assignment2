{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec128a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL MODEL COMPARISON\n",
      "====================================================\n",
      "                 Model  Accuracy     AUC  Precision  Recall  F1 Score     MCC\n",
      "1        Decision Tree    0.2802  0.5319     0.0737  0.0856    0.0784  0.1941\n",
      "2                  KNN    0.3188  0.6033     0.1214  0.1017    0.1061  0.2352\n",
      "0  Logistic Regression    0.3285  0.7156     0.0812  0.0857    0.0825  0.2290\n",
      "3          Naive Bayes    0.0580  0.5550     0.0389  0.0724    0.0309  0.0403\n",
      "4        Random Forest    0.3961  0.6839     0.1371  0.1117    0.1154  0.2997\n",
      "5              XGBoost    0.3671  0.6080     0.1035  0.0969    0.0976  0.2711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load Dataset\n",
    "# -------------------------------\n",
    "df = pd.read_csv(\"D:/BitsAssignments/ML/Assignmnet-2/mixed_desc.csv\")\n",
    "\n",
    "# Drop ID column\n",
    "df = df.drop(columns=['CIDs'])\n",
    "\n",
    "# Target column\n",
    "# Target column\n",
    "target_col = 'EC1_EC2_EC3_EC4_EC5_EC6'\n",
    "\n",
    "# âœ… DEFINE X and y first\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# ---------------------------------\n",
    "# THEN apply cleaning\n",
    "# ---------------------------------\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.fillna(X.mean())\n",
    "X = X.clip(lower=-1e6, upper=1e6)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Encode labels\n",
    "# -------------------------------\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Remove rare classes (important)\n",
    "# -------------------------------\n",
    "counts = Counter(y)\n",
    "valid_classes = [c for c, cnt in counts.items() if cnt > 1]\n",
    "\n",
    "mask = [label in valid_classes for label in y]\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Train/Test split\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Scaling (for LR & KNN)\n",
    "# -------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Evaluation Function\n",
    "# -------------------------------\n",
    "def evaluate_model(name, model, X_test_input, y_test):\n",
    "    \n",
    "    y_pred = model.predict(X_test_input)\n",
    "    y_prob = model.predict_proba(X_test_input)\n",
    "\n",
    "    # basic metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    # AUC calculation (robust multi-class handling)\n",
    "    test_classes = np.unique(y_test)\n",
    "    class_indices = [list(model.classes_).index(c) for c in test_classes]\n",
    "    y_prob_filtered = y_prob[:, class_indices]\n",
    "\n",
    "    if len(test_classes) == 2:\n",
    "        auc = roc_auc_score(y_test, y_prob_filtered[:, 1])\n",
    "    else:\n",
    "        y_test_bin = label_binarize(y_test, classes=test_classes)\n",
    "        auc = roc_auc_score(y_test_bin, y_prob_filtered, multi_class='ovr', average='macro')\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": round(acc, 4),\n",
    "        \"AUC\": round(auc, 4),\n",
    "        \"Precision\": round(precision, 4),\n",
    "        \"Recall\": round(recall, 4),\n",
    "        \"F1 Score\": round(f1, 4),\n",
    "        \"MCC\": round(mcc, 4)\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Train all models\n",
    "# -------------------------------\n",
    "results = []\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=5000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "results.append(evaluate_model(\"Logistic Regression\", lr, X_test_scaled, y_test))\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "results.append(evaluate_model(\"Decision Tree\", dt, X_test, y_test))\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "results.append(evaluate_model(\"KNN\", knn, X_test_scaled, y_test))\n",
    "\n",
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "results.append(evaluate_model(\"Naive Bayes\", nb, X_test, y_test))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "results.append(evaluate_model(\"Random Forest\", rf, X_test, y_test))\n",
    "\n",
    "# XGBoost\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "results.append(evaluate_model(\"XGBoost\", gb, X_test, y_test))\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Print Results Table\n",
    "# -------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nFINAL MODEL COMPARISON\")\n",
    "print(\"====================================================\")\n",
    "print(results_df.sort_values(by=\"Model\", ascending=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
